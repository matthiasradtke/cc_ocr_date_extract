{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR - Date Extraction - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find in the collection of pdfs following entities:\n",
    "1. Belegdatum = Rechnungsdatum \n",
    "2. Abrechnugnsperiode = JJJJMM von TTMMJJJ des Leistungsdatums (Lieferdatum)\n",
    "Or\n",
    "3. Referenznummer = Rechnungsnummer \n",
    "\n",
    "First, we only consider \"Belegdatum\"\n",
    "\n",
    "## Steps\n",
    "    * Load data into pandas\n",
    "    * finde dates using regex\n",
    "    * Maybe first use only first page (using all just takes longer)\n",
    "    * get span of text before (maybe after) found date\n",
    "    * tokenize span\n",
    "    * build vectorizer\n",
    "    * learn model using token words vector\n",
    "    * Predict\n",
    "    * use other features: \n",
    "        * number of white space around found date\n",
    "        * position of match wrt page (upper part, lower part, left, right)\n",
    "        * (on which page found)\n",
    "        * How close to other found dates and in which order (first found date)\n",
    "\n",
    "    * First determine language of document, than use date format accordingly\n",
    "    \n",
    "### Possible Tweaks\n",
    "    * Not only use tokens left and right in same line but tokens nearby: \"Lieferdatum\" could be above in table\n",
    "    * Modify image before ocr\n",
    "    * Use different detection method for pdfs with text layer compared to scanned images\n",
    "    * Use different tesseract options\n",
    "    * Use table detection of documents\n",
    "    * Use lexicon approach\n",
    "    * Use HOCR output: hocr = pytesseract.image_to_pdf_or_hocr('test.png', extension='hocr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "# Adding tesseract custom options\n",
    "custom_config = r'--oem 1 --psm 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auswertung = pd.read_excel('../data/01_raw/Auswertung.XLSX')\n",
    "df_auswertung['pdf_number_pages'] = 0\n",
    "df_auswertung['pdf_text'] = ''\n",
    "\n",
    "files = glob.glob(\"../data/01_raw/KTA AI Rechnungen/*.pdf\")\n",
    "df_files = pd.DataFrame({'file_path': files})\n",
    "df_files['file_name'] = df_files['file_path'].apply(lambda x: os.path.split(x)[1])\n",
    "df_files['file_number'] = df_files['file_name'].apply(lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "df_full = (pd.merge(df_auswertung, df_files, left_on='Dokumentnummer', right_on='file_number')\n",
    "          .drop(['Dokumentnummer', 'Dokumentenbezeichnung'], axis=1))\n",
    "\n",
    "# Train Test Split\n",
    "df = df_full.sample(frac=0.8, random_state=42)\n",
    "df_validate = df_full.drop(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(s):\n",
    "    result = re.sub(r'\\s+\\n', ' ', s)\n",
    "    return result\n",
    "\n",
    "def doOcr(file_path):\n",
    "    text = ''\n",
    "    \n",
    "    doc = convert_from_path(file_path)\n",
    "    path, file_name = os.path.split(file_path)\n",
    "    file_base_name, _ = os.path.splitext(file_name)\n",
    "    file_number = int(file_base_name)\n",
    "\n",
    "    page_number = 0\n",
    "    for page_data in doc:\n",
    "        page_number+=1\n",
    "        page_text = pytesseract.image_to_string(page_data, config=custom_config)\n",
    "        text += f\"\\n\\n\\n {page_text}\"\n",
    "            \n",
    "    return page_number, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = r'--oem 1 --psm 13'\n",
    "temp = doOcr(\"../data/01_raw/KTA AI Rechnungen/5672950.pdf\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.head(2).copy()\n",
    "df_test[['pdf_number_pages', 'pdf_text']] = df_test.apply(lambda r: doOcr(r['file_path']), axis=1, result_type='expand')\n",
    "df_test['pdf_text'] = df_test['pdf_text'].apply(clean_text)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Spacy Tokenizer\n",
    "Make sure that date formats including / - . infixes survive tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = '''we have an invoice no:123451\\n,as well as \n",
    "a date 2020/11/20, another 11/20/2020 09-06-2020 09.06.2020.'''\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_md\")\n",
    "# Modify tokenizer\n",
    "suffixes = list(nlp.Defaults.suffixes)\n",
    "# remove dot as suffix\n",
    "suffixes.append('\\.')\n",
    "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search\n",
    "\n",
    "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER, HYPHENS\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
    "# modify tokenizer infix patterns\n",
    "infixes = (LIST_ELLIPSES + LIST_ICONS + [\n",
    "        # EDIT: Removed hypen \\- : r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[0-9])[+\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
    "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "        ),\n",
    "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "        r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
    "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "    ]\n",
    ")\n",
    "infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_re.finditer\n",
    "\n",
    "doc = nlp.make_doc(test_doc)\n",
    "print([t for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find matching dates and get features\n",
    "Parse dates from text and get all date matches with left and right span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "import dateparser\n",
    "\n",
    "test_doc = '''date 2020-09-11 2012.01.09 2020/12/31 we have an invoice no:123451\\n,as well as \n",
    "a , 2011-10-20  20-April-2020 1211.12.31 11.13.12 another 12/14/2020 13/12/2020 09-06-2020 09.06.2020.'''\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# tested: https://regexr.com/32t3r\n",
    "# mm/dd/yyyy m/d/yy\n",
    "#pattern1 = [{\"TEXT\": {\"REGEX\": r\"^(?:(1[0-2]|0?[1-9])[.\\-\\/]{1}(3[01]|[12][0-9]|0?[1-9]))[.\\-\\/]{1}(?:[0-9]{2})?[0-9]{2}$\"}}]\n",
    "# dd/mm/yyyy d/m/yy\n",
    "#pattern2 = [{\"TEXT\": {\"REGEX\": r\"^(?:(3[01]|[12][0-9]|0?[1-9])[.\\-\\/]{1}(1[0-2]|0?[1-9]))[.\\-\\/]{1}(?:[0-9]{2})?[0-9]{2}$\"}}]\n",
    "# yyyy/mm/dd\n",
    "#pattern5 = [{\"TEXT\": {\"REGEX\": r\"^(?:(1[0-2]|0?[1-9])[.\\-\\/]{1}(3[01]|[12][0-9]|0?[1-9]))[.\\-\\/]{1}(?:[0-9]{2})?[0-9]{2}$|^(?:(3[01]|[12][0-9]|0?[1-9])[.\\-\\/]{1}(1[0-2]|0?[1-9]))[.\\-\\/]{1}(?:[0-9]{2})?[0-9]{2}$\"}}]\n",
    "pattern5 = [{\"TEXT\": {\"REGEX\": r\"^(?:(1[0-2]|0?[1-9])[.\\-\\/]{1}(3[01]|[12][0-9]|0?[1-9]))[.\\-\\/]{1}(?:[0-9]{2})?[0-9]{2}$|^(?:(3[01]|[12][0-9]|0?[1-9])[.\\-\\/]{1}(1[0-2]|0?[1-9]))[.\\-\\/]{1}(?:[0-9]{2})?[0-9]{2}$\"}}]\n",
    "pattern3 = [{\"TEXT\": {\"REGEX\": r\"^(?:[1-9]{1}[0-9]{3})[.\\-\\/]{1}(?:(1[0-2]|0?[1-9])[.\\-\\/]{1}(3[01]|[12][0-9]|0?[1-9]))$\"}}]\n",
    "# dd-Mon-yyyy e.g. 20-Jun-2020\n",
    "months = r\"(Jan(uary)?|Feb(ruary)?|Mar(ch)?|Apr(il)?|May|Jun(e)?|Jul(y)?|Aug(ust)?|Sep(tember)?|Oct(ober)?|Nov(ember)?|Dec(ember)?)\"\n",
    "pattern4 = [{\"TEXT\": {\"REGEX\": fr\"^(?:(3[01]|[12][0-9]|0?[1-9])[.\\-\\/]{{1}}({months}))[.\\-\\/]{{1}}(?:[0-9]{{2}})?[0-9]{{2}}$\"}}]\n",
    "\n",
    "            \n",
    "#matcher.add(\"Date: (mm/dd/yyyy m/d/yy)\", None, pattern1)\n",
    "#matcher.add(\"Date: (dd/mm/yyyy d/m/yy)\", None, pattern2)\n",
    "matcher.add(\"Date: (__/__/yyyy _/_/yy)\", None, pattern5)\n",
    "matcher.add(\"Date: (yyyy/mm/dd)\", None, pattern3)\n",
    "matcher.add(\"Date: (dd-Mon-yyyy)\", None, pattern4)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_date(string: str) -> datetime:\n",
    "    # TODO: use match_id to better parse the date, also use language\n",
    "    from dateparser import parse\n",
    "    # date_formats = [\"%d/%m/%Y\", \"%d/%m/%y\", \"%m/%d/%Y\", \"%m/%d/%y\", \"%Y/%m/%d\", \"%d-%B-%Y\", \"d-%b-%Y\"]\n",
    "    date = parse(string, languages=['de'])\n",
    "    if not date:\n",
    "        date = parse(string)\n",
    "    return date\n",
    "    \n",
    "def get_date_matches_from_text(text: str, n_lefts:int=2, n_rights:int=1) -> pd.DataFrame:\n",
    "    doc = nlp.make_doc(text)\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    all_matches = []\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        # The matched span (text)\n",
    "        match_string = doc[start:end].text\n",
    "        match_date = parse_date(match_string)\n",
    "        match_date = match_date.strftime('%Y-%m-%d')\n",
    "        span_left = doc[max(0, start-n_lefts):max(0, end-1)]\n",
    "        span_right = doc[end:min(len(doc), end+n_rights)]\n",
    "        all_matches.append({\n",
    "            'match_id': nlp.vocab.strings[match_id],\n",
    "            'match_date': match_date,\n",
    "            'text_left': span_left.text,\n",
    "            'text_right': span_right.text,\n",
    "        })\n",
    "\n",
    "    return all_matches\n",
    "\n",
    "doc = nlp.make_doc(test_doc)\n",
    "print([t for t in doc])\n",
    "\n",
    "df_matches = get_date_matches_from_text(test_doc, 4)\n",
    "df_matches[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_langdetect import LanguageDetector\n",
    "#\n",
    "text = 'This is an english text.'\n",
    "text1 = 'Das ist ein deutscher text.'\n",
    "text2 = 'Esto es un texto espanol.'\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "doc = nlp(text1)\n",
    "\n",
    "doc._.language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sample pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = df.sample(2, random_state=0)\n",
    "test_pdf[['pdf_number_pages', 'pdf_text']] = test_pdf.apply(lambda r: doOcr(r['file_path']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!open \"../data/01_raw/KTA AI Rechnungen/5672190.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/05_model_input/train_formatted.csv')\n",
    "print(len(df_train), df_train.value_counts('label'))\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "vectorizer_text = TfidfVectorizer(analyzer='char',\n",
    "                                  lowercase=True,\n",
    "                                  ngram_range=(1,2),\n",
    "                                  max_df = 0.8,\n",
    "                                  max_features=1000,\n",
    "                                  min_df=3,\n",
    "                                  strip_accents=None, #'unicode',\n",
    "                                  norm='l2',\n",
    "                                  sublinear_tf=True)\n",
    "\n",
    "# Pipeline\n",
    "# Model Selection\n",
    "classifier = LogisticRegression(penalty='l2')\n",
    "\n",
    "# Feature Selection\n",
    "features = vectorizer_text\n",
    "\n",
    "#feature_selection = SelectKBest(chi2, k=100),\n",
    "#feature_selection = SelectFromModel(RandomForestClassifier(n_estimators=100)),\n",
    "feature_selection = None\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('features', DataFrameMapper([\n",
    "        ('text', vectorizer_text),\n",
    "#        (['ratioNumAlph'], sklearn.preprocessing.StandardScaler()),\n",
    "    ])),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('clf', classifier),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(df_train, df_train['label'])\n",
    "\n",
    "df_eval = df_train.copy()\n",
    "df_eval['prediction'] = pipe.predict(df_train)\n",
    "\n",
    "classes = list(pipe.classes_)\n",
    "df_eval['prediction_int'] = df_eval['prediction'].apply(lambda l: classes.index(l))\n",
    "\n",
    "df_eval = pd.concat([df_eval, pd.DataFrame(pipe.predict_proba(df_eval))],axis=1)\n",
    "df_eval['predict_probab'] = df_eval.apply(lambda r: r[r['prediction_int']], axis=1)\n",
    "\n",
    "df_eval['predict_probab'] = pipe.predict_proba(df_eval)[:,0]\n",
    "\n",
    "print(\"All dates:\")\n",
    "print(len(df_eval), len(pd.unique(df_eval['file_number'])))\n",
    "\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def get_single_date_for_doc(g):\n",
    "    # first only consider predicted belegdatum, as this is what we want to have..\n",
    "    result = g.query(\"prediction == 'Belegdatum'\")\n",
    "    if len(result) == 0:\n",
    "        # if no belegdatum predicted, use dates where the label is belegdatum\n",
    "        result = g.query(\"label == 'Belegdatum'\")\n",
    "        if len(result) == 0:\n",
    "            result = g\n",
    "    # reduce \n",
    "    result = result.loc[result['predict_probab'].idxmax()]\n",
    "    return result\n",
    "        \n",
    "df_docs = df_eval.groupby('file_number').apply(get_single_date_for_doc)\n",
    "\n",
    "print(\"All documents:\")\n",
    "print(len(df_docs), len(pd.unique(df_docs['file_number'])))\n",
    "\n",
    "    # TP: Belegdatum predicted correctly\n",
    "    # FP: Belegdatum predicted incorrectly\n",
    "    # TN: Correct absence of Belegdatum (maybe ocr problem)\n",
    "    # FN: No Belegdatum predicted (missing result)\n",
    "    \n",
    "print('tn:',len(df_docs.query(\"label == 'other_date' & prediction == 'other_date'\")),\n",
    "      'fp:',len(df_docs.query(\"label == 'other_date' & prediction == 'Belegdatum'\")),\n",
    "      'fn:',len(df_docs.query(\"label == 'Belegdatum' & prediction == 'other_date'\")),\n",
    "      'tp:',len(df_docs.query(\"label == 'Belegdatum' & prediction == 'Belegdatum'\")))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(df_docs['label'], df_docs['prediction'],\n",
    "                 labels=['other_date','Belegdatum']).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def find_threshold(df_, p=0.95):\n",
    "    # Find prediction threshold so that accuracy for documents above is equal to p\n",
    "    predict_proba = pipe.predict_proba(df_)[:, 0]\n",
    "    for t in np.arange(0, 1.01, 0.01):\n",
    "        df_['prediction_t'] = ['Belegdatum' if v >= t else 'other_date' for v in predict_proba]\n",
    "        df_test = df_.query(\"prediction_t == 'Belegdatum'\")\n",
    "        acc = round(accuracy_score(df_test['label'], df_test['prediction_t']), 2)\n",
    "        if acc >= p:\n",
    "            n_correct_docs_tuned = accuracy_score(df_test['label'], df_test['prediction_t'], normalize=False)\n",
    "            n_docs_we_trust_tuned = len(df_test)\n",
    "\n",
    "            return n_correct_docs_tuned, n_docs_we_trust_tuned, acc\n",
    "\n",
    "find_threshold(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "    # TP: Belegdatum predicted correctly\n",
    "    # FP: Belegdatum predicted incorrectly\n",
    "    # TN: Correct absence of Belegdatum (maybe ocr problem)\n",
    "    # FN: No Belegdatum predicted (missing result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/cc_ocr_date_extract/pipelines/ml/\")\n",
    "import nodes\n",
    "from nodes import evaluate_model\n",
    "\n",
    "import importlib\n",
    "importlib.reload(nodes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(evaluate_model(pipe, df_train))\n",
    "\n",
    "#tn: 38 fp: 11 fn: 60 tp: 199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_validate(pipe, X, y):\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import make_scorer\n",
    "    scoring = {'prec_macro': 'precision_macro',\n",
    "               'rec_macro': make_scorer(recall_score, average='macro')}\n",
    "    scores = cross_validate(pipe, X, y, scoring=scoring, cv = 5, return_train_score = True)\n",
    "    scores = {k: f\"{v.mean().round(2)} +- {v.std().round(2)}\" for (k,v) in scores.items()}\n",
    "    return scores\n",
    "    \n",
    "pprint(train_cross_validate(pipe, df_train.dropna(), df_train.dropna()['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/05_model_input/test_formatted.csv')\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(pipe, df_test, df_test['label']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_test.reset_index(drop=True).copy()\n",
    "df_['prediction'] = pipe.predict(df_test)\n",
    "df_['prediction_probab_belegdatum'] = pd.DataFrame(pipe.predict_proba(df_))[0]\n",
    "df_['prediction_probab_other_date'] = pd.DataFrame(pipe.predict_proba(df_))[1]\n",
    "df_.hist(['prediction_probab_belegdatum','prediction_probab_other_date'], bins=50);\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "disp = plot_confusion_matrix(pipe, df_test, df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/calibration.html#calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve,  CalibratedClassifierCV\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "prob_pos = pipe.predict_proba(df_)[:,1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(df_test['label'], prob_pos, n_bins=20)\n",
    "\n",
    "ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\")\n",
    "\n",
    "ax2.hist(prob_pos, range=(0, 1), bins=20, histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Vorhersage\")\n",
    "ax2.set_ylabel(\"Anzahl\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipe.predict(df_train.dropna())\n",
    "\n",
    "df_eval = df_train.dropna().reset_index(drop=True).copy()\n",
    "df_eval['prediction'] = prediction\n",
    "df_eval['prediction_probab'] = pd.DataFrame(pipe.predict_proba(df_eval))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number duplicate training examples\n",
    "print(\"training examples:\", len(df_train))\n",
    "print(\"number duplicates:\", len(df_train)-len(df_train.drop_duplicates('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_pred_probab = (df_eval.sort_values('prediction_probab')\n",
    "                      .groupby(['file_number','prediction'])\n",
    "                      .last()\n",
    "                      .reset_index())\n",
    "\n",
    "\n",
    "df_tt = (df_max_pred_probab[df_max_pred_probab\n",
    "                       .groupby('file_number')\n",
    "                       .apply(lambda x: ~x['label'].isin(['Belegdatum']))\n",
    "                       .reset_index()['label']])\n",
    "df_tt[df_tt['file_number'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open \"../data/01_raw/KTA AI Rechnungen/5672563.pdf\" ## very many pages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open \"../data/01_raw/KTA AI Rechnungen/5671953.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.query('file_number == 5671953')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.query('file_number == 5671953')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('file_number == 5671953')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
